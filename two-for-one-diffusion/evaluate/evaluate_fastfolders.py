import argparse
import json
import warnings
from datetime import datetime
import torch
import wandb
import numpy as np
import mdtraj as md
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from os.path import join
from deeptime.clustering import MiniBatchKMeans
from deeptime.markov import TransitionCountEstimator, pcca
from sklearn.preprocessing import normalize
from scipy.spatial.distance import jensenshannon
from pathlib import Path
import os
import sys
import math
from rmsd import kabsch_rotate
from IPython.display import Image as IPImage, display
from PIL import Image
from tqdm import tqdm
from collections import defaultdict
import heapq
from matplotlib.colors import ListedColormap

sys.path.insert(0, "")

from models import CommittorNN, GraphTransformer

from evaluate.evaluators import (
    PwdEvaluator,
    TicEvaluator,
    RmsdEvaluator,
    ContactEvaluator,
    PhysicalEvaluator,
    get_pwd_triu_batch,
    js_divergence,
)

from evaluate.msm_utils import (
    find_min_flux_states,
    discretize_trajectory,
    sample_tp,
    get_tp_likelihood,
    get_tp_log_likelihood,
    compute_shannon_entropy,
)

from datasets.dataset_utils_empty import (
    Molecules,
    AtomSelection,
    DEShawDataset,
    to_angstrom,
    norm_stds,
)

from utils import center_zero
from logging_utils import save_ovito_traj

# OM Paper plotting stuff
import scienceplots
import matplotlib.pylab as pylab

params = {
    "figure.dpi": 600,
    "axes.labelsize": "small",
    "legend.fontsize": "x-small",
    "axes.titlesize": "medium",
    "xtick.labelsize": "x-large",
    "ytick.labelsize": "x-large",
    "font.family": "DejaVu Sans",
}
from matplotlib import rc

pylab.rcParams.update(params)


# default cluster endpoints for testing interpolation
# (obtained by visual inspection of what are hard transition paths to capture)
CLUSTER_ENDPOINTS = {
    "chignolin": [11, 13],
    "trp_cage": [2, 13],
    "bba": [9, 17],
    "villin": [0, 17],
    "protein_g": [11, 14],
}

CLUSTER_ENDPOINTS_ALL_ATOM = {
    "chignolin": [11, 8],
    "trp_cage": [2, 4],
    "bba": [14, 12],
    # "villin": [0, 17],
    # "protein_g": [11, 14],
}

PDB_ID_TO_NAME = {
    "cln025": "chignolin",
    "2jof": "trp_cage",
    "1fme": "bba",
    "2f4k": "villin",
    "1mi0": "protein_g",
}


def evaluate_fastfolders(
    protein_name,
    gen_mode,
    append_exp_name,
    checkpoint_folder,
    reference_folder,
    pdb_folder,
    atom_selection=AtomSelection.A_CARBON,
    subsample=0,
    n_sims=-1,
    opt_steps=0,
    window_size=3,
    gif=True,
    model=None,
    num_paths=8,
    traj_len=20,
    endpoints=None,
    log=False,
):
    """
    Top-level function to evaluate the samples/interpolation paths generated by various methods.
    """
    # Set the random seed for reproducibility of k-means clustering
    np.random.seed(0)

    original_subsample = subsample

    if "interpolate" in gen_mode:
        assert subsample == 0, "Subsampling is not supported for interpolation"
    # Adjust number of paths for iid and langevin generation
    if "interpolate" not in gen_mode:
        num_paths = 1
    if "om_interpolate" not in gen_mode:
        assert (
            opt_steps == 0
        ), "Truncating optimization steps is only supported for OM interpolation"

    append_exp_name_str = "_" + append_exp_name if append_exp_name else ""
    all_atom_append = "_all_atom" if atom_selection == AtomSelection.PROTEIN else ""
    eval_folder = os.path.join(
        checkpoint_folder,
        f"{protein_name+all_atom_append}/main_eval_output_{gen_mode}{append_exp_name_str}",
    )

    gt_traj_path = os.path.join(
        "./datasets/torch_trajectories",
        Molecules[protein_name.upper()].value,
        f"gt_traj{all_atom_append}.pt",
    )
    if os.path.exists(gt_traj_path):
        gt_traj = 10 * torch.tensor(torch.load(gt_traj_path))
    else:
        print("Loading ground truth trajectory")
        # Load the reference dataset
        dataset = DEShawDataset(
            data_root="./datasets/Reference_MD_Sims",
            molecule=Molecules[protein_name.upper()],
            simulation_id=0,
            atom_selection=atom_selection,
            return_bond_graph=False,
            transform=to_angstrom,
            align=False,
        )
        torch.save(
            dataset.traj.xyz,
            gt_traj_path,
            _use_new_zipfile_serialization=False,
            pickle_protocol=5,
        )

        gt_traj = 10 * dataset.traj.xyz  # convert to angstroms
    gt_traj -= gt_traj.mean(1, keepdims=True)  # center

    # Define starting and ending states for interpolation
    if endpoints is not None:
        start, end = endpoints
    else:
        cluster_endpoints_path = Path(
            os.path.join(
                reference_folder,
                f"saved_cluster_endpoints_{protein_name.upper()}{all_atom_append}.npy",
            )
        )

    gt_prob_matrix_path = Path(
        os.path.join(
            reference_folder,
            f"saved_transition_matrix_{protein_name.upper()}{all_atom_append}.npy",
        )
    )
    if gt_prob_matrix_path.exists():
        gt_prob_matrix = np.load(gt_prob_matrix_path)

        kmeans_cluster_centers = np.load(
            os.path.join(
                reference_folder,
                f"saved_cluster_centers_{protein_name.upper()}{all_atom_append}.npy",
            )
        )

    else:
        # Compute the necessary values from the reference simulation data
        print("Computing reference values...")
        (gt_prob_matrix, kmeans_cluster_centers) = dynamics_analysis(
            protein_name,
            reference_folder,
            pdb_folder,
            sampled_mol=None,
            atom_selection=atom_selection,
            num_clusters=20,
            gt_traj=gt_traj,
        )
    if endpoints is None:
        # cluster_endpoints = np.load(cluster_endpoints_path)
        cluster_endpoints = (
            CLUSTER_ENDPOINTS[protein_name]
            if atom_selection == AtomSelection.A_CARBON
            else CLUSTER_ENDPOINTS_ALL_ATOM[protein_name]
        )
        start, end = cluster_endpoints[0], cluster_endpoints[1]

    # Get TIC evaluator
    tic_evaluator = TicEvaluator(
        val_data=None,
        mol_name=protein_name,
        eval_folder=eval_folder,
        data_folder=pdb_folder,
        atom_selection=atom_selection,
        folded_pdb_folder=os.path.join(pdb_folder, "folded_pdbs"),
        bins=101,
        evalset="testset",
    )

    # Load data
    if gen_mode == "langevin":
        subsample = int(
            subsample * 1000
        )  # convert from nanoseconds to frames (simulations were saved every 1 ps)
    if gen_mode == "gt":
        eval_folder = os.path.join(
            checkpoint_folder, f"{protein_name}{all_atom_append}/main_eval_output_gt"
        )
        os.makedirs(eval_folder, exist_ok=True)
        sampled_mol = torch.tensor(gt_traj)
        subsample = int(
            subsample * 5
        )  # convert from nanoseconds to frames (GT simulations are saved every 200 ps)
    else:
        append_exp_name_str = "_" + append_exp_name if append_exp_name else ""
        eval_folder = os.path.join(
            checkpoint_folder,
            f"{protein_name}{all_atom_append}/main_eval_output_{gen_mode}{append_exp_name_str}",
        )
        sample_path = Path(eval_folder, f"sample-{gen_mode}.pt")

        # Load sampled molecules
        sampled_mol = torch.load(sample_path)

    pdb_file = os.path.join(
        pdb_folder,
        f"folded_pdbs/{Molecules[protein_name.upper()].value}-0-{atom_selection.value}.pdb",
    )

    if opt_steps != 0:
        # sample from an intermediate point in the optimization trajectory
        path_history = Path(eval_folder, f"path_history-{gen_mode}.pt")
        path_history = torch.load(path_history)
        sampled_mol = path_history[opt_steps // 50]

    if subsample != 0:
        if gen_mode == "langevin":
            # 100 parallel langevin sims were generated
            # take the first subsample frames from the first n_sims sims
            sampled_mol = sampled_mol.reshape(
                100, -1, sampled_mol.shape[1], sampled_mol.shape[2]
            )
            sampled_mol = sampled_mol[:n_sims, :subsample].reshape(
                -1, sampled_mol.shape[2], sampled_mol.shape[3]
            )
        else:
            sampled_mol = sampled_mol[:subsample]
    n_atoms = sampled_mol.shape[1]

    # Load topology from pdb file
    topology = md.load(pdb_file).topology

    # Load committor probabilities
    committor_probs_file = os.path.join(
        reference_folder, f"{protein_name}_committor_probs_{start}_{end}.npy"
    )
    bin_committor_probs = None
    if os.path.exists(committor_probs_file):
        bin_committor_probs = np.load(committor_probs_file)

    # Load GT transition ensemble TIC coordinates
    gt_transition_ensemble_file = os.path.join(
        reference_folder, f"{protein_name}_{start}_{end}_transition_ensemble_TICA.npy"
    )
    gt_transition_ensemble = None
    if os.path.exists(gt_transition_ensemble_file):
        gt_transition_ensemble = np.load(gt_transition_ensemble_file)

    n_ref_samples = 1000

    # Discretize the interpolation trajectory based on the reference cluster centers
    cluster_assignments, transformed_samples = discretize_trajectory(
        sampled_mol, tic_evaluator, kmeans_cluster_centers
    )

    no_transition = False

    if gen_mode == "iid":
        sampled_traj = cluster_assignments  # don't need to subsample
    elif gen_mode == "langevin" or gen_mode == "gt":
        # Fit a MSM to the generated samples, using the reference cluster centers
        (prob_matrix, _) = dynamics_analysis(
            protein_name,
            reference_folder,
            pdb_folder,
            sampled_mol,
            num_clusters=20,
            atom_selection=atom_selection,
            gt_cluster_assignments=cluster_assignments,
            lagtime=(
                200 if gen_mode == "langevin" else 1
            ),  # langevin sims were saved every 1 ps, reference was saved every 200 ps
        )
        if (
            prob_matrix.shape[0] < 20
            or (prob_matrix[end] == 0).all()
            or (prob_matrix[start] == 0).all()
        ):
            no_transition = True
            sampled_traj = None
            warnings.warn("No transition between start and end states found.")
        else:
            try:
                sampled_traj = sample_tp(
                    prob_matrix, start, end, traj_len, n_ref_samples
                )
            except ValueError:  # no transition found
                sampled_traj = None
                no_transition = True
                warnings.warn("No transition between start and end states found.")
    else:  # interpolate or om_interpolate
        cluster_assignments = cluster_assignments.reshape(num_paths, -1)
        sampled_traj = cluster_assignments[
            :, :: math.ceil(cluster_assignments.shape[1] / (traj_len - 1))
        ]
        # add the last state to the end of the trajectory
        sampled_traj = np.concatenate(
            [sampled_traj, cluster_assignments[:, -1:]], axis=1
        )

    # Sample transition paths from the reference MSM
    ref_sampled_traj = sample_tp(gt_prob_matrix, start, end, traj_len, n_ref_samples)
    ref_entropy = compute_shannon_entropy(ref_sampled_traj)
    ref_path_probabilities = get_tp_likelihood(ref_sampled_traj, gt_prob_matrix).prod(
        -1
    )
    ref_path_log_probabilities = get_tp_log_likelihood(
        ref_sampled_traj, gt_prob_matrix
    ).sum(-1)
    entropy = None

    if no_transition:
        jsd = 1
        transition_jsd = 1
        path_probabilities = np.zeros(sampled_mol.shape[0])
        path_log_probabilities = -np.inf * np.ones(sampled_mol.shape[0])
        fraction_valid_paths = 0

    else:
        # Compute entropy of the sampled trajectories (proxy for diversity)
        if "interpolate" in gen_mode:
            entropy = compute_shannon_entropy(sampled_traj)

        # Compute JSD between the state distributions of the reference and generated paths
        sampled_state_dist = np.array(
            [np.count_nonzero(sampled_traj == i) for i in range(20)]
        )
        sampled_state_dist = sampled_state_dist / sampled_state_dist.sum()
        ref_state_dist = np.array(
            [np.count_nonzero(ref_sampled_traj == i) for i in range(20)]
        )
        ref_state_dist = ref_state_dist / ref_state_dist.sum()
        jsd = jensenshannon(ref_state_dist, sampled_state_dist)

        # Compute the JSD restricted to the transition ensemble of the reference and generated paths (defined as committor probs between 0.45 and 0.55)
        bins_x = np.digitize(transformed_samples[:, 0], tic_evaluator.bin_edges_x)
        bins_y = np.digitize(transformed_samples[:, 1], tic_evaluator.bin_edges_y)
        bins_x = np.clip(bins_x, 0, tic_evaluator.bins - 1)
        bins_y = np.clip(bins_y, 0, tic_evaluator.bins - 1)
        bin_idx = bins_x * tic_evaluator.bins + bins_y

        transition_jsd = -1
        if bin_committor_probs is not None:
            transition_ensemble_mask = np.logical_and(
                bin_committor_probs[bin_idx] > 0.45, bin_committor_probs[bin_idx] < 0.55
            )
            transition_ensemble = transformed_samples[transition_ensemble_mask]
            transition_ensemble_mols = center_zero(
                sampled_mol[transition_ensemble_mask]
            ).numpy()

            # align the transition ensemble to the first frame
            for i in range(transition_ensemble_mols.shape[0]):
                transition_ensemble_mols[i] = kabsch_rotate(
                    transition_ensemble_mols[i], sampled_mol[0]
                )

            # save transition ensemble as a pdb
            transition_ensemble_mols = md.Trajectory(
                transition_ensemble_mols / 10, topology=topology
            )
            transition_ensemble_mols.save_pdb(
                str(str(eval_folder) + f"/transition_ensemble.pdb")
            )

            # save transition ensemble TICA coordinates
            np.save(
                str(str(eval_folder) + f"/transition_ensemble_TICA.npy"),
                transition_ensemble,
            )

            transition_ensemble, _ = discretize_trajectory(
                transition_ensemble,
                tic_evaluator,
                kmeans_cluster_centers,
                transform=False,
            )
            transition_state_dist = np.array(
                [np.count_nonzero(transition_ensemble == i) for i in range(20)]
            )
            transition_state_dist = transition_state_dist / transition_state_dist.sum()

            if gt_transition_ensemble is not None:
                gt_transition_ensemble, _ = discretize_trajectory(
                    gt_transition_ensemble,
                    tic_evaluator,
                    kmeans_cluster_centers,
                    transform=False,
                )
                ref_transition_state_dist = np.array(
                    [np.count_nonzero(gt_transition_ensemble == i) for i in range(20)]
                )

                ref_transition_state_dist = (
                    ref_transition_state_dist / ref_transition_state_dist.sum()
                )
                transition_jsd = jensenshannon(
                    ref_transition_state_dist, transition_state_dist
                )

        # Compute the likelihood of the sampled trajectories under the reference MSM
        path_probabilities = None
        path_log_probabilities = None
        fraction_valid_paths = None
        if gen_mode != "iid":
            path_probabilities = get_tp_likelihood(sampled_traj, gt_prob_matrix).prod(
                -1
            )

            path_log_probabilities = get_tp_log_likelihood(
                sampled_traj, gt_prob_matrix
            ).sum(-1)

            # Percentage of valid (non-zero probability) paths
            fraction_valid_paths = (
                path_probabilities[path_probabilities > 0].shape[0]
                / path_probabilities.shape[0]
            )

    # Physicality metrics
    (
        fraction_unphysical,
        fraction_bond_length_issues,
        fraction_bond_angle_issues,
        fraction_distance_issues,
        fraction_rg_issues,
    ) = (None, None, None, None, None)
    if "interpolate" in gen_mode:
        physical_eval = PhysicalEvaluator(gt_traj)
        physical_dict = {}
        for traj in sampled_mol.reshape(num_paths, -1, sampled_mol.shape[-2], 3):
            # Validate the current trajectory
            results = physical_eval.validate(traj)

            # Aggregate results
            for key, value in results.items():
                if key not in physical_dict:
                    physical_dict[key] = value
                else:
                    # Concatenate boolean tensors along the frame dimension
                    physical_dict[key] = torch.cat((physical_dict[key], value), dim=0)

        fraction_unphysical = physical_dict["unphysical_frames"].sum() / len(
            physical_dict["unphysical_frames"]
        )
        fraction_bond_length_issues = physical_dict["bond_length_issues"].sum() / len(
            physical_dict["bond_length_issues"]
        )
        fraction_bond_angle_issues = physical_dict["bond_angle_issues"].sum() / len(
            physical_dict["bond_angle_issues"]
        )
        fraction_distance_issues = physical_dict["distance_issues"].sum() / len(
            physical_dict["distance_issues"]
        )
        fraction_rg_issues = physical_dict["rg_issues"].sum() / len(
            physical_dict["rg_issues"]
        )

    # Visualize the model-produced interpolation along with a subset of 20 reference/generated paths
    max_free_energies = None
    transition_rates = None
    if "gt" not in gen_mode:
        free_energies, transition_rates = get_tic_free_energy_plots(
            protein_name,
            gen_mode,
            append_exp_name,
            checkpoint_folder,
            reference_folder,
            pdb_folder,
            atom_selection,
            sampled_mol,
            opt_steps=opt_steps,
            gen_paths=(
                kmeans_cluster_centers[sampled_traj[:20]]
                if ("langevin" in gen_mode or "gt" in gen_mode) and not no_transition
                else None
            ),
            ref_paths=kmeans_cluster_centers[ref_sampled_traj[:8]],
            bin_committor_probs=bin_committor_probs,
            gif=gif,
            window_size=window_size,
            num_paths=num_paths,
            log=log,
        )

        max_free_energies = np.array(
            [np.max(free_energy_profile) for free_energy_profile in free_energies]
        )

    # Save final metrics to a JSON file

    metrics = {
        "Max Free Energy (kBT) Mean: ": (
            max_free_energies.mean() if max_free_energies is not None else None
        ),
        "Max Free Energy (kBT) Std: ": (
            max_free_energies.std() if max_free_energies is not None else None
        ),
        "Fraction of Physical Paths: ": (
            1 - fraction_unphysical.item() if fraction_unphysical is not None else None
        ),
        "Fraction of Paths with Physical Bond Lengths: ": (
            1 - fraction_bond_length_issues.item()
            if fraction_bond_length_issues is not None
            else None
        ),
        "Fraction of Paths with Physical Bond Angles: ": (
            1 - fraction_bond_angle_issues.item()
            if fraction_bond_angle_issues is not None
            else None
        ),
        "Fraction of Paths with Physical Inter-Residue Distances: ": (
            1 - fraction_distance_issues.item()
            if fraction_distance_issues is not None
            else None
        ),
        "Fraction of Paths with Physical Radius of Gyration: ": (
            1 - fraction_rg_issues.item() if fraction_rg_issues is not None else None
        ),
        "Transition Rate Mean: ": (
            transition_rates.mean() if transition_rates is not None else None
        ),
        "Transition Rate Std: ": (
            transition_rates.std()
            if "interpolate" in gen_mode and transition_rates is not None
            else None
        ),
        "Path Probability Mean": (
            path_probabilities.mean() if path_probabilities is not None else None
        ),
        "Valid Path Probability Mean": (
            path_probabilities[path_probabilities > 0].mean()
            if path_probabilities is not None
            else None
        ),
        "Path Probability Std": (
            path_probabilities.std() if path_probabilities is not None else None
        ),
        "Path Negative Log Probability Mean (Normalized)": (
            -path_log_probabilities.mean() / (sampled_traj.shape[1] - 1)
            if path_log_probabilities is not None and sampled_traj is not None
            else None
        ),
        "Valid Path Negative Log Probability Mean (Normalized)": (
            -path_log_probabilities[path_probabilities > 0].mean()
            / (sampled_traj.shape[1] - 1)
            if path_log_probabilities is not None and sampled_traj is not None
            else None
        ),
        "Reference Path Negative Log Probability Mean": (
            -ref_path_log_probabilities.mean()
            if ref_path_log_probabilities is not None
            else None
        ),
        "Reference Path Negative Log Probability Mean (Normalized)": (
            -ref_path_log_probabilities.mean() / (ref_sampled_traj.shape[1] - 1)
            if ref_path_log_probabilities is not None and ref_sampled_traj is not None
            else None
        ),
        "Fraction of Valid Paths": fraction_valid_paths,
        "Jensen-Shannon Divergence of State Distributions": jsd,
        "Jensen-Shannon Divergence of Transition Ensemble State Distributions": transition_jsd,
        "Transition Path Entropy (Diversity)": entropy,
        "Reference Transition Path Entropy (Diversity)": ref_entropy,
    }

    subsample_append = (
        f"_subsample_{int(original_subsample)}" if original_subsample != 0 else ""
    )
    if original_subsample != 0 and gen_mode != "iid":
        subsample_append += f"ns"

    final_metrics_file = (
        f"final_metrics_traj_len={traj_len}" + subsample_append + ".json"
    )

    with open(join(eval_folder, final_metrics_file), "w") as f:
        json.dump(metrics, f, indent=4)

    if log:
        wandb.log(metrics)


def get_tic_free_energy_plots(
    protein_name,
    gen_mode,
    append_exp_name,
    checkpoint_folder,
    reference_folder,
    pdb_folder,
    atom_selection,
    sampled_mol,
    opt_steps=0,
    gen_paths=None,
    ref_paths=None,
    bin_committor_probs=None,
    window_size=7,
    gif=False,
    num_paths=8,
    log=False,
):
    """
    Produces a TIC plot of the samples generated by the model, along with a reference interpolation path if provided.
    Also produces a free energy curve along the generated interpolation path.
    If gif is set to True, it will create a GIF of the Onsager-Machlup optimization process.
    """

    # Load data
    append_exp_name_str = "_" + append_exp_name if append_exp_name else ""
    all_atom_append = "_all_atom" if atom_selection == AtomSelection.PROTEIN else ""
    eval_folder = os.path.join(
        checkpoint_folder,
        f"{protein_name}{all_atom_append}/main_eval_output_{gen_mode}{append_exp_name_str}",
    )
    sample_path = Path(eval_folder, f"sample-{gen_mode}.pt")
    pdb_file = os.path.join(
        pdb_folder,
        f"folded_pdbs/{Molecules[protein_name.upper()].value}-0-{atom_selection.value}.pdb",
    )
    n_atoms = sampled_mol.shape[1]

    # Load topology from pdb file
    topology = md.load(pdb_file).topology

    start, end = (
        CLUSTER_ENDPOINTS[protein_name]
        if atom_selection == AtomSelection.A_CARBON
        else CLUSTER_ENDPOINTS_ALL_ATOM[protein_name]
    )

    # Load pretrained committor model
    device = (
        torch.device(torch.cuda.current_device())
        if torch.cuda.is_available()
        else torch.device("cpu")
    )
    model = GraphTransformer(num_beads=n_atoms, hidden_nf=64, conservative=True)
    committor_model = None
    committor_state_dict_file = os.path.join(
        checkpoint_folder,
        protein_name + all_atom_append,
        f"committor-model-{start}_{end}.pt",
    )
    if os.path.exists(committor_state_dict_file):
        committor_model = CommittorNN(model)
        state_dict = torch.load(
            committor_state_dict_file, map_location=device, weights_only=False
        )

        committor_model.load_state_dict(state_dict.state_dict())
        committor_model.to(device)

    # store endpoints if interpolation is used
    if "interpolate" in gen_mode:
        endpoints = sampled_mol.reshape(num_paths, -1, n_atoms, 3)[
            :, [0, -1]
        ].numpy()  # [num_paths, 2, n_atoms, 3]

    # Initialize evaluator
    tic_evaluator = TicEvaluator(
        val_data=None,
        mol_name=protein_name,
        eval_folder=eval_folder,
        data_folder=pdb_folder,
        atom_selection=atom_selection,
        folded_pdb_folder=os.path.join(pdb_folder, "folded_pdbs"),
        bins=101,
        evalset="testset",
    )  # The evalset is the set we'll compare to in the next evaluation steps

    loop = [sampled_mol]
    # Load path along optimization if OM interpolation is used
    if gif and gen_mode == "om_interpolate":
        path_history = Path(eval_folder, f"path_history-{gen_mode}.pt")
        path_history = torch.load(path_history)
        loop = path_history[: (opt_steps // 50)] if opt_steps != 0 else path_history
        if isinstance(loop, dict):
            loop = loop["tr"].cpu()  # keep only alpha carbon coords

    # Compute and save reference TIC plot
    ref_fig = tic_evaluator._plot_tic(
        tic_evaluator.gt_prob,
        endpoints=None,  # ref_paths[:, [0, -1]] if "interpolate" in gen_mode else None,
        gen_paths=gen_paths,
        ref_paths=None,
        file_name=join(tic_evaluator.plots_folder, "TICA_reference.png"),
        title="Reference testset",
        save_plot=True,
    )

    free_energies = []

    # Create unique timestamped folder (to avoid overwriting with concurrent runs)
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    gif_folder = f"temp_gif_images_{timestamp}"
    os.makedirs(gif_folder, exist_ok=True)

    tic_paths = []  # To keep track of the TIC image paths for creating a GIF
    free_energy_paths = (
        []
    )  # To keep track of the free energy image paths for creating a GIF
    committor_paths = (
        []
    )  # To keep track of the committor image paths for creating a GIF
    dihedral_hist_paths = (
        []
    )  # To keep track of the dihedral angle histograms for creating a GIF
    pwd_hist_paths = (
        []
    )  # To keep track of the pairwise distance histograms for creating a GIF
    transition_rate_paths = (
        []
    )  # To keep track of the transition rate box plots for creating a GIF

    mean_transition_rates = []
    nn_committor_probs = []

    for i, path in tqdm(enumerate(loop)):
        # Get samples TIC free energy landscape

        sample_tic_features = tic_evaluator.get_tic_features(
            path, tic_evaluator.folded, separate=False
        )

        # sample_tic_features = np.hstack((dihedrals, pwds))
        transformed_samples = tic_evaluator.tica(sample_tic_features)

        # Find the bins of the samples
        bins_x = np.digitize(transformed_samples[:, 0], tic_evaluator.bin_edges_x)
        bins_y = np.digitize(transformed_samples[:, 1], tic_evaluator.bin_edges_y)
        # clip the bins to the maximum bin index
        bins_x = np.clip(bins_x, 0, tic_evaluator.bins - 1)
        bins_y = np.clip(bins_y, 0, tic_evaluator.bins - 1)
        bin_idx = bins_x * tic_evaluator.bins + bins_y

        path_committor_probs = None
        if bin_committor_probs is not None:
            path_committor_probs = bin_committor_probs[bin_idx]

        # probabilities of the samples as a function of path position
        gt_probs = np.zeros((path.shape[0],))

        # probabilities of the samples as a function of TICA bins
        prob_samp = np.zeros((tic_evaluator.bins, tic_evaluator.bins))

        padding = window_size // 2
        # Iterate over path
        for t in range(path.shape[0]):
            # Get the bin indices
            x_bin = bins_x[t]
            y_bin = bins_y[t]

            if tic_evaluator.gt_prob[x_bin, y_bin] != 0:
                # Ground truth probability in this bin is non-zero
                gt_probs[t] = tic_evaluator.gt_prob[x_bin, y_bin]
                prob_samp[x_bin, y_bin] = tic_evaluator.gt_prob[x_bin, y_bin]

            else:
                # Define the window boundaries
                x_min = max(0, x_bin - padding)
                x_max = min(tic_evaluator.gt_prob.shape[0] - 1, x_bin + padding)
                y_min = max(0, y_bin - padding)
                y_max = min(tic_evaluator.gt_prob.shape[1] - 1, y_bin + padding)

                # Extract the window
                window = tic_evaluator.gt_prob[x_min : x_max + 1, y_min : y_max + 1]

                # Find the minimum non-zero probability in the window
                non_zero_probs = window[window > 0]

                if non_zero_probs.size > 0:
                    # Set the minimum non-zero value in gt_probs
                    gt_probs[t] = np.min(non_zero_probs)
                    prob_samp[x_bin, y_bin] = np.min(non_zero_probs)
                else:
                    # If no non-zero values found, set gt_probs to 0
                    gt_probs[t] = 0
                    prob_samp[x_bin, y_bin] = 0

        # Calculate and plot the TIC landscape
        file_name = join(gif_folder, f"TICA_sampled_{i}.png")
        tic_evaluator._plot_tic(
            prob_samp,
            endpoints=endpoints if "interpolate" in gen_mode else None,
            gen_paths=gen_paths,
            ref_paths=None,  # ref_paths,
            file_name=file_name,
            title="Samples",
            save_plot=True,
        )  # Save the plot

        tic_paths.append(file_name)

        device = (
            torch.device(torch.cuda.current_device())
            if torch.cuda.is_available()
            else torch.device("cpu")
        )
        transition_rates = None
        committor_model = None  # don't do rate stuff now
        if committor_model is not None:
            norm_grads = []
            pred_probs = []
            for x in path.split(256):
                x = (x - x.mean(1, keepdim=True)) / norm_stds[
                    Molecules[protein_name.upper()]
                ]
                x = x.requires_grad_(True).to(device)
                h = torch.eye(x.shape[-2]).to(device)
                t = torch.zeros((x.shape[0],)).to(device)
                pred_prob = committor_model(x, h, t)
                grad_prob = torch.autograd.grad(
                    outputs=pred_prob,  # [batch_size, ]
                    inputs=x,  # [batch_size, n_nodes, 3]
                    grad_outputs=torch.ones_like(pred_prob),
                    retain_graph=True,  # Make sure the graph is not destroyed during training
                    create_graph=True,  # Create graph for second derivative
                    allow_unused=True,
                )[0].detach()
                pred_probs.append(pred_prob.detach())
                norm_grads.append(grad_prob.reshape(x.shape[0], -1).norm(dim=1))

            transition_rates = (
                torch.cat(norm_grads, dim=0).cpu().numpy().astype(np.float64)
            )
            mean_transition_rates.append(
                transition_rates.reshape(num_paths, -1).mean(-1)
            )
            pred_probs = torch.cat(pred_probs).reshape(num_paths, -1).cpu().numpy()
            nn_committor_probs.append(pred_probs)

            # Box plot of transition rates
            plt.figure()
            plt.boxplot(transition_rates)
            plt.ylim(1e-6, 1e-1)
            plt.yscale("log")
            plt.title(f"Step {i}: Transition rates")
            plt.ylabel("Transition rate / (kBT / gamma)")
            plt.show()
            file_name = join(gif_folder, f"transition_rates_{i}.png")
            plt.savefig(file_name)
            plt.close()
            transition_rate_paths.append(file_name)

        # Calculate and plot the free energy profile along the path
        free_energy_profile = -np.log(gt_probs + np.exp(-10))
        free_energies.append(free_energy_profile)
        plt.figure()
        # plot free energy profile of all paths
        for profile in torch.tensor(free_energy_profile).chunk(num_paths):
            plt.plot(profile)
        plt.ylim(-6, 11)
        plt.xlabel("Path Step")
        plt.ylabel("Free energy / kBT")
        plt.title(f"Step {i}: Transition free energy profile: {protein_name}")
        plt.axhline(10, color="red", linestyle="--", label="Zero Probability Threshold")
        plt.legend()
        plt.show()
        file_name = join(gif_folder, f"free_energy_{i}.png")
        plt.savefig(file_name)
        plt.close()
        free_energy_paths.append(file_name)

        # Plot the committor function along the path
        if path_committor_probs is not None:
            plt.figure()

            mean_committor_probs = (
                torch.tensor(path_committor_probs).reshape(num_paths, -1).mean(0)
            )
            plt.plot(mean_committor_probs)
            plt.ylim(-0.1, 1.1)
            plt.xlabel("Path Step")
            plt.ylabel("Committor Probability")
            plt.title(f"Step {i}: Transition free energy profile: {protein_name}")
            plt.axhline(0, color="blue", linestyle="--", label="Starting State")
            plt.axhline(1, color="red", linestyle="--", label="Ending State")
            plt.legend()
            plt.show()
            file_name = join(gif_folder, f"path_committor_{i}.png")
            plt.savefig(file_name)
            plt.close()
            committor_paths.append(file_name)

    # Save mean transition rates
    if mean_transition_rates:
        mean_transition_rates = np.stack(mean_transition_rates)
        nn_committor_probs = np.stack(nn_committor_probs)
        path_committor_probs = path_committor_probs.reshape(num_paths, -1)
        np.save(
            join(tic_evaluator.plots_folder, "path_committor_probs.npy"),
            path_committor_probs,
        )
        np.save(
            join(tic_evaluator.plots_folder, "mean_transition_rates.npy"),
            mean_transition_rates,
        )
        np.save(
            join(tic_evaluator.plots_folder, "nn_committor_probs.npy"),
            nn_committor_probs,
        )

    # Create a GIF from the saved TICA images
    tica_gif_path = join(tic_evaluator.plots_folder, "tica_samples.gif")
    images = [Image.open(tic_path) for tic_path in tic_paths]

    # Save as GIF
    images[0].save(
        tica_gif_path,
        save_all=True,
        append_images=images[1:],
        optimize=False,
        duration=200,  # Duration for each frame in milliseconds
        loop=0,  # Loop forever
    )

    # Repeat for the free energy images
    free_energy_gif_path = join(tic_evaluator.plots_folder, "free_energy.gif")
    images = [Image.open(free_energy_path) for free_energy_path in free_energy_paths]

    # Save as GIF
    images[0].save(
        free_energy_gif_path,
        save_all=True,
        append_images=images[1:],
        optimize=False,
        duration=100,  # Duration for each frame in milliseconds
        loop=0,  # Loop forever
    )

    # Repeat for the committor images
    committor_gif_path = join(tic_evaluator.plots_folder, "path_committor.gif")
    images = [Image.open(committor_path) for committor_path in committor_paths]

    # Save as GIF
    if images:
        images[0].save(
            committor_gif_path,
            save_all=True,
            append_images=images[1:],
            optimize=False,
            duration=100,  # Duration for each frame in milliseconds
            loop=0,  # Loop forever
        )

    # Repeat for the transition rate box plots
    transition_rate_gif_path = join(tic_evaluator.plots_folder, "transition_rates.gif")
    images = [
        Image.open(transition_rate_path)
        for transition_rate_path in transition_rate_paths
    ]

    # Save as GIF
    if images:
        images[0].save(
            transition_rate_gif_path,
            save_all=True,
            append_images=images[1:],
            optimize=False,
            duration=100,  # Duration for each frame in milliseconds
            loop=0,  # Loop forever
        )

    # Repeat for the dihedral angle histograms
    dihedral_hist_gif_path = join(tic_evaluator.plots_folder, "dihedral_hist.gif")
    images = [
        Image.open(dihedral_hist_path) for dihedral_hist_path in dihedral_hist_paths
    ]
    if images:
        images[0].save(
            dihedral_hist_gif_path,
            save_all=True,
            append_images=images[1:],
            optimize=False,
            duration=100,  # Duration for each frame in milliseconds
            loop=0,  # Loop forever
        )

    # Repeat for the pairwise distance histograms
    pwd_hist_gif_path = join(tic_evaluator.plots_folder, "pwd_hist.gif")
    images = [Image.open(pwd_hist_path) for pwd_hist_path in pwd_hist_paths]
    if images:
        images[0].save(
            pwd_hist_gif_path,
            save_all=True,
            append_images=images[1:],
            optimize=False,
            duration=100,  # Duration for each frame in milliseconds
            loop=0,  # Loop forever
        )

    # Save the GIFs to the wandb run
    if log:
        log_dict = {
            "Reference TICA": wandb.Image(
                join(tic_evaluator.plots_folder, "TICA_reference.png")
            ),
            "TICA Samples": wandb.Image(tica_gif_path),
            "Free Energy Profiles": wandb.Image(free_energy_gif_path),
        }
        if os.path.exists(transition_rate_gif_path):
            log_dict["Transition Rates"] = wandb.Image(transition_rate_gif_path)

        wandb.log(log_dict)

    # Remove the temporary image files
    for image_path in (
        tic_paths
        + free_energy_paths
        + dihedral_hist_paths
        + pwd_hist_paths
        + transition_rate_paths
        + committor_paths
    ):
        os.remove(image_path)

    # Delete the gif folder
    os.rmdir(gif_folder)

    return free_energies, transition_rates


def dynamics_analysis(
    protein_name,
    reference_folder,
    pdb_folder,
    sampled_mol,
    atom_selection,
    num_clusters=None,
    gt_traj=None,
    gt_cluster_assignments=None,
    lagtime=1,
):
    """
    Analyze the dynamics of a set of samples.
    Create a Markov State Model (MSM) by clustering the samples in TIC-space and counting the transitions between clusters.
    Returns the transition probability matrix and the cluster centers.
    """

    # Load data
    all_atom_append = "_all_atom" if atom_selection == AtomSelection.PROTEIN else ""

    if num_clusters is None:
        num_clusters = num_clusters_per_protein[protein_name]

    if gt_traj is not None:
        eval_folder = reference_folder
        sampled_mol = torch.tensor(gt_traj)
    pdb_file = os.path.join(
        pdb_folder,
        f"folded_pdbs/{Molecules[protein_name.upper()].value}-0-{atom_selection.value}.pdb",
    )

    n_atoms = sampled_mol.shape[1]

    # Load topology from pdb file
    topology = md.load(pdb_file).topology

    # Since we need to do K-means clustering in TIC-space, we will transform the samples first

    # Initialize TIC evaluator
    tic_evaluator = TicEvaluator(
        val_data=None,
        mol_name=protein_name,
        eval_folder=None,
        data_folder=pdb_folder,
        atom_selection=atom_selection,
        folded_pdb_folder=os.path.join(pdb_folder, "folded_pdbs"),
        bins=101,
        evalset="testset",
        gt_traj=gt_traj / 10 if gt_traj is not None else None,
    )  # The evalset is the set we'll compare to in the next evaluation steps

    # Get samples TIC free energy landscape
    print("Computing TIC features for samples...")
    sample_tic_features = tic_evaluator.get_tic_features(
        sampled_mol, tic_evaluator.folded, separate=False
    )

    transformed_samples = tic_evaluator.tica(sample_tic_features)

    if gt_cluster_assignments is None:
        # K-means clustering
        print("Performing k-means clustering of samples in TIC-space...")
        kmeans = MiniBatchKMeans(
            n_clusters=num_clusters,
            max_iter=0,
            batch_size=64,
            init_strategy="kmeans++",
            n_jobs=16,
            tolerance=1e-7,
        )
        assignments = kmeans.fit_transform(transformed_samples)
    else:
        assignments = gt_cluster_assignments

    # Create MSM with k-means cluster assignments
    print("Creating Markov State Model...")
    count_matrix = TransitionCountEstimator.count(
        count_mode="sliding", dtrajs=[assignments.astype("int")], lagtime=lagtime
    )
    count_matrix = normalize(count_matrix, axis=1, norm="l1")

    if gt_traj is not None:
        start_cluster_idx, end_cluster_idx = find_min_flux_states(count_matrix)
        np.save(
            os.path.join(
                reference_folder,
                f"saved_cluster_endpoints_{protein_name.upper()}{all_atom_append}.npy",
            ),
            np.array([start_cluster_idx, end_cluster_idx]),
        )

        # Also save the transition matrix
        np.save(
            os.path.join(
                reference_folder,
                f"saved_transition_matrix_{protein_name.upper()}{all_atom_append}.npy",
            ),
            count_matrix,
        )

    if gt_cluster_assignments is not None:
        kmeans_cluster_centers = None
    else:
        kmeans_cluster_centers = kmeans._model.cluster_centers

    if gt_traj is not None:
        # Save the cluster centers for the reference simulation
        if kmeans_cluster_centers is not None:
            np.save(
                os.path.join(
                    reference_folder,
                    f"saved_cluster_centers_{protein_name.upper()}{all_atom_append}.npy",
                ),
                kmeans_cluster_centers,
            )

    return count_matrix, kmeans_cluster_centers


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--protein_name",
        type=str,
        default="chignolin",
        help="Name of the protein to evaluate",
    )

    parser.add_argument(
        "--atom_selection",
        type=str,
        default="c-alpha",
        help="Level of coarse-graining, either 'c-alpha' or 'protein'",
    )

    parser.add_argument(
        "--gen_mode",
        type=str,
        default="om_interpolate",
        help="Generation mode (iid, langevin, interpolate, om_interpolate)",
    )
    parser.add_argument(
        "--append_exp_name",
        type=str,
        default=None,
        help="Append experiment name to the saved model folder",
    )

    parser.add_argument(
        "--reference_folder",
        type=str,
        default="/home/sanjeevr/om-diffusion/two-for-one-diffusion/evaluate/saved_references",
        help="Folder where the reference data is saved",
    )

    parser.add_argument(
        "--pdb_folder",
        type=str,
        default="/home/sanjeevr/om-diffusion/two-for-one-diffusion/datasets",
        help="Folder where the folded pdb data is saved",
    )

    parser.add_argument(
        "--subsample",
        type=int,
        default=0,
        help="First n samples to evaluate (0 means all samples). For langevin and gt modes, this is the number of nanoseconds to keep per sim",
    )

    parser.add_argument(
        "--n_sims",
        type=int,
        default=-1,
        help="First n simulations to evaluate (-1 means all simulations). Only used for langevin mode",
    )

    parser.add_argument(
        "--num_paths",
        type=int,
        default=8,
        help="Number of paths generated by the model. Only used for interpolate and om_interpolate modes",
    )

    parser.add_argument(
        "--traj_len",
        type=int,
        default=20,
        help="Length of the discretized trajectories for evaluation. Affects JSD, valid path, and path probability metrics",
    )

    parser.add_argument(
        "--opt_steps",
        type=int,
        default=0,
        help="First n timesteps of OM optimization trajectory to evaluate (0 means full trajectory). Only used for om_interpolate mode",
    )

    parser.add_argument(
        "--disable_logging", action="store_true", help="Don't log to wandb"
    )
    parser.add_argument(
        "--no_gif", action="store_true", help="Don't create a GIF of the optimization"
    )

    args = parser.parse_args()

    append = "_" + args.append_exp_name if args.append_exp_name else ""
    subsample_append = (
        f"_subsample_{int(args.subsample)}" if args.subsample != 0 else ""
    )
    if args.subsample != 0 and args.gen_mode != "iid":
        subsample_append += f"ns"

    opt_steps_append = (
        f"_opt_steps={int(args.opt_steps)}" if args.opt_steps != 0 else ""
    )

    all_atom_append = f"_all-atom" if args.atom_selection == "protein" else ""

    if not args.disable_logging:
        wandb.login()
        wandb.init(
            project="fastfolders",
            name=args.protein_name
            + "_"
            + args.gen_mode
            + append
            + subsample_append
            + opt_steps_append
            + all_atom_append,
            config=args,
        )

    checkpoint_folder = "/home/sanjeevr/om-diffusion/two-for-one-diffusion/saved_models"

    new_append = append + subsample_append + opt_steps_append

    atom_selection = (
        AtomSelection.A_CARBON
        if args.atom_selection == "c-alpha"
        else AtomSelection.PROTEIN
    )

    evaluate_fastfolders(
        args.protein_name,
        args.gen_mode,
        args.append_exp_name,
        checkpoint_folder,
        args.reference_folder,
        args.pdb_folder,
        atom_selection,
        args.subsample,
        args.n_sims,
        args.opt_steps,
        log=not args.disable_logging,
        gif=not args.no_gif,
        num_paths=args.num_paths,
        traj_len=args.traj_len,
    )

    print("Evaluation complete.")
